{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pytorch gradient test\n",
    "Check how gradient calculation is working in mid-layers.\n",
    "Below stream is,\n",
    "\n",
    "$$x \\xrightarrow{func(x)} z \\xrightarrow{func2(z)} y$$\n",
    "\n",
    "I want to know $$\\frac{\\partial y}{\\partial z}$$, and $$\\frac{\\partial y}{\\partial x}$$.\n",
    "\n",
    "First, import torch and define input 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.ones(1, requires_grad = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "or do like,"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1.], requires_grad=True)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(1)\n",
    "x.requires_grad_(True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, define `grad()`.\n",
    "`tensor.register_hook(grad)` give the tensor's gradient to grad() as param."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# saved gradients. stacked from back.\n",
    "grads = []\n",
    "\n",
    "# save gradients.\n",
    "def grad(grad):\n",
    "    grads.append(grad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, define $$func(x)$$ and $$func2(z)$$.  \n",
    "And regist hook.  \n",
    "\n",
    "$$func(x) = 2x$$  \n",
    "\n",
    "$$func2(z) = z^2 + 2z + 2$$  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch.utils.hooks.RemovableHandle at 0x7f7bb3575320>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def func(x):\n",
    "    z = 2 * x\n",
    "    z.register_hook(grad)\n",
    "    return z\n",
    "\n",
    "def func2(z):\n",
    "    y = (z ** 2) + (2 * z) + 2\n",
    "    y.register_hook(grad)\n",
    "    return y\n",
    "\n",
    "x.register_hook(grad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, feed x to $$func(x)$$ and $$func2(z)$$."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "z = func(x)\n",
    "y = func2(z)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, calculate gradient!\n",
    "After Tensor.backward(), gradients of x ,z will be saved at `grads`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "y.backward()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "See grads."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([1.]), tensor([6.]), tensor([12.])]\n"
     ]
    }
   ],
   "source": [
    "print(grads)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Because of backward(), gradients are saved from backside.\n",
    "$$grad[0] = \\frac{\\partial y}{\\partial y}$$\n",
    "\n",
    "$$grad[1] = \\frac{\\partial y}{\\partial z}$$\n",
    "\n",
    "$$grad[2] = \\frac{\\partial y}{\\partial x}$$\n",
    "\n",
    "First, $$\\frac{\\partial y}{\\partial y} = 1$$,\n",
    "\n",
    "Next, $$\\frac{\\partial y}{\\partial z} = 2z+2$$.\n",
    "Because of $$func(x)$$, input of $$func2(z)$$ is 2 ($$2 \\times 1$$),\n",
    "So, $$\\frac{\\partial y}{\\partial z} = 6$$\n",
    "\n",
    "Finally, $$\\frac{\\partial y}{\\partial x} = \\frac{\\partial y}{\\partial z}\\frac{\\partial z}{\\partial x}$$,\n",
    "$$\\frac{\\partial y}{\\partial z} = 2z+2$$ and $$\\frac{\\partial z}{\\partial x} =2$$\n",
    "So, $$\\frac{\\partial y}{\\partial x} = 4z+4$$,\n",
    "Because of $$func(x)$$, $$z = 2x = 2$$,\n",
    "So,  $$\\frac{\\partial y}{\\partial x} = 4 \\times 2 + 4 = 12$$\n",
    "\n",
    "### Result\n",
    "So if we want to know gradient of mid layers output $$n$$ and value $$m$$, $$\\frac{\\partial m}{\\partial n}$$,\n",
    "Use `m.backward()` and `n.register_hook(grad)`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}